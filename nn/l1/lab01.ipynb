{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPFI7tXJG75N"
      },
      "source": [
        "# Wstęp\n",
        "Pierwsze laboratorium dotyczy wprowadzenia do środowiska PyTorch. Z uwagi na fakt, że przygotowanie środowiska może zająć dłuższą chwilę, część ta jest opisana na końcu niniejszej instrukcji i należy ją wykonać w domu (sekcja [Zadanie domowe](#homework)). Ćwiczenie to nie podlega ocenie, natomiast sugerowane jest wykonanie wszystkich poleceń w celu zapoznania się z podstawami operacji na tensorach. Przed przystąpieniem do realizacji zadań należy wykonać następujące kroki:\n",
        "\n",
        "\n",
        "1.   Uruchomić [Dysk Google](https://drive.google.com/).\n",
        "2.   Przesłać na [Dysk Google](https://drive.google.com/) plik **lab01.ipynb**.\n",
        "3.   Kliknąć prawym przyciskiem myszy na plik **lab01.ipynb** na Dysku Google i wybrać opcję **Otwórz za pomocą** a następnie **Google Colaboratory**. <br/>\n",
        "![colab.png](https://drive.google.com/uc?id=1XzvyggTWZ9j_1I3EegeXK1fu2uBAUSZi)\n",
        "4.   W menu **Google Colab** wybrać opcję **Runtime**, a następnie **Change runtime type**. <br/>\n",
        "![runtime_type.png](https://drive.google.com/uc?id=1Ldp2Je0eFZEUTyGxG3xWoYluq1jCv734)\n",
        "5.   Z rozwijanej listy **Hardware accelerator** wybrać **GPU** a następnie **SAVE**. <br/>\n",
        "![runtime_gpu.png](https://drive.google.com/uc?id=10IY3WEJJ8UVyVHhPkOgZkR6XlPakV5V5)\n",
        "6.   Na końcu należy wybrać opcję **Connect**. <br/>\n",
        "![runtime_gpu.png](https://drive.google.com/uc?id=1juOcGKNVqNJRpoKOg-KCNns15YVHI0vC) <br/>\n",
        "Gdy przycisk **Connect** zamieni się w status widoczny na poniższym obrazku, można rozpocząć pracę. <br/>\n",
        "![runtime_gpu.png](https://drive.google.com/uc?id=1w_ERPHdqD0-_fXBnI6zZR9rTPRujA3c4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tensory\n",
        "Tensory są strukturami danych, które są bardzo podobne do tablic i macierzy. W środowisku **PyTorch** tensory są wykorzystywane do zapisywania danych wejściowych i wyjściowych modelu, jak również jego parametrów. Tensory są podobne do tablic **NumPy**, z tą różnicą, że tensory mogą być uruchamiane na kartach graficznych  lub innym wyspecjalizowanym sprzęcie w celu przyspieszenia obliczeń. Przed rozpoczęciem prac należy zaimportować bibliotekę **PyTorch**. Dla przedstawienia pewnych analogii zaimportowana będzie również biblioteka **NumPy**.\n",
        "\n",
        "Ustaw kursor na polu z kodem poniżej i wciśnij przycisk ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABsAAAAYCAIAAACEIhGsAAAA+0lEQVRIDb2VMQ7DMAhFezbPyc7OWWD3Wdi5RW6RnbVSLaE44DRtrXqIIoKf/zfYedjs8ZgNtL8TRYSZEbG8BiIys6peOBtqVFUAaKD4BIARNyfWWiMlRmqtUWxCvIlrC0TomaiqUct15GT/TEz3ziuTogHg6L0jikg6Z993Iko/teBRZkccTWsSRGRd15RLRC6zI47cefa2bWkOInpOR0zXL6V4tpmNdsBzviEyc1w7J6aOjho/dv22MsuyRHWllGFlLronder0YfeY2eQON7P5p9DMJt8UrQluQuPFYzb+K0y+cb1dVZWIvE8RkYiOlfVMf+nOjEd/eXkCRZH2n46ZamIAAAAASUVORK5CYII=)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N589VyKOFCMq"
      },
      "outputs": [],
      "source": [
        "import torch # biblioteka PyTorch\n",
        "import numpy as np # biblioteka NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAw-0AZNIFqD"
      },
      "source": [
        "## Inicjalizacja tensora\n",
        "Tensory mogą być inicjalizowane na wiele różnych sposobów. Przykładowo:\n",
        "### Bezpośrednio z listy\n",
        "Tensory mogą być tworzone bezpośrednio z listy. Typ danych jest określany automatycznie.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZWfy7d-bIAxT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 5],\n",
              "        [3, 6],\n",
              "        [4, 7]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_list = [[2,5],[3,6],[4,7]] # lista list z elementami w postaci liczb całkowitych\n",
        "data_tensor = torch.tensor(data_list) # utworzenie tensora z listy\n",
        "data_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Pwr5XljXqla"
      },
      "source": [
        "Utworzony tensor reprezentuje macierz o wymiarach 3x2:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 \\\\\n",
        "3 & 6 \\\\\n",
        "4 & 7\n",
        "\\end{bmatrix}$\n",
        "\n",
        "Wymiar tensora można sprawdzić następująco:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sNC4MYhPYwEj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_tensor.shape # kształt tensora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgqvUPfnZMpa"
      },
      "source": [
        "Do elementów **shape** odwołujemy się jak w przypadku listy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TP0h-B5aZDOf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_tensor.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kqw-OUL5ZKIs"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_tensor.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi3lQcVyWX3H"
      },
      "source": [
        "### Z tablicy NumPy\n",
        "Tensory można również tworzyć z tablicy NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9_EJGZQpIC01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 5],\n",
              "        [3, 6],\n",
              "        [4, 7]], dtype=torch.int32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "numpy_array = np.array(data_list) # tablica NumPy utworzona z listy\n",
        "data_tensor = torch.from_numpy(numpy_array) # tensor utworzony z tablicy NumPy\n",
        "data_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzmld7uPXAw5"
      },
      "source": [
        "Tensor można również skonwertować do tablicy NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kirprDjqKiQ9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2, 5],\n",
              "       [3, 6],\n",
              "       [4, 7]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np_arr = data_tensor.numpy() # tablica NumPy utworzona z tensora\n",
        "np_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph0C8kRoaO_1"
      },
      "source": [
        "---\n",
        "**ZADANIE 1**\n",
        "\n",
        "Uzupełnij kod poniżej, by zmienna **my_tensor** była tensorem reprezentującym następującą macierz:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "2 & 4 & 6\\\\\n",
        "1 & 3 & 5 \\\\\n",
        "\\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-ZH8987OLoik"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 4, 6],\n",
              "        [1, 3, 5]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_tensor = torch.tensor(\n",
        "    [[2, 4, 6],\n",
        "     [1, 3, 5]]\n",
        ")\n",
        "my_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzD3gPVJbXip"
      },
      "source": [
        "---\n",
        "### Z innego tensora\n",
        "Domyślnie nowy tensor zachowuje wszystkie właściwości (kształt, typ danych) tensora przekazanego jako argument. Można nadpisać pewne właściwości podczas tworzenia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "l2ZQ9x1PbWp0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1],\n",
              "        [1, 1],\n",
              "        [1, 1]], dtype=torch.int32)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_2 = torch.ones_like(data_tensor) # tworzenie tensora o wymiarze data_tensor wypełnionego wartościami 1\n",
        "tensor_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sEtwjaqFeI7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]], dtype=torch.float16)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_3 = torch.ones_like(data_tensor, dtype=torch.float16) # j.w. z wartościami typu float16\n",
        "tensor_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oNAx1VnSeohu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]], dtype=torch.float16)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_4 = torch.clone(tensor_3) # kopia tensora tensor_3\n",
        "tensor_4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6-TwelzhYcf"
      },
      "source": [
        "W ostatnim przypadku warto zajrzeć do dokumentacji metody [torch.clone](https://pytorch.org/docs/stable/generated/torch.clone.html) oraz [detach](https://pytorch.org/docs/stable/autograd.html#torch.Tensor.detach)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF8syRqygKxN"
      },
      "source": [
        "### Z wartościami losowymi bądź stałymi\n",
        "Zmienna **tensor_shape** jest krotką, reprezentującą wymiary tensora. W poniższych funkcjach jest przekazywana jako argument, określający wymiar tworzonego tensora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ne7cyFmFgJ_C"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.1168, 0.6626],\n",
              "         [0.5643, 0.6338],\n",
              "         [0.3534, 0.6778]],\n",
              "\n",
              "        [[0.3875, 0.9981],\n",
              "         [0.0128, 0.6430],\n",
              "         [0.1802, 0.5637]]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_shape = (2,3,2) # interpretacja: dwie macierze o wymiarze 3x2\n",
        "tensor_random = torch.rand(tensor_shape) # tensor o losowych wartościach z rozkładu jednorodnego\n",
        "tensor_random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6wv1_bPYeHTp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1., 1.],\n",
              "         [1., 1.],\n",
              "         [1., 1.]],\n",
              "\n",
              "        [[1., 1.],\n",
              "         [1., 1.],\n",
              "         [1., 1.]]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_ones = torch.ones(tensor_shape) # tensor o wartościach równych 1\n",
        "tensor_ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TlTPsAhnj1r5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.]]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_zeros = torch.zeros(tensor_shape) # tensor o wartościach równych 0\n",
        "tensor_zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGYDXMHFj_aK"
      },
      "source": [
        "---\n",
        "**ZADANIE 2**\n",
        "\n",
        "Utwórz kształt **my_shape_2**, a na jego podstawie taki tensor **my_tensor_2** o wartościach losowych, by kształt macierzy wyjściowej był taki jak podanej poniżej:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "0 & 0\\\\\n",
        "0 & 0\\\\\n",
        "0 & 0\\\\\n",
        "\\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XVlHka1mLofx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_shape_2 = (3, 2)\n",
        "my_tensor_2 = torch.zeros(my_shape_2)\n",
        "my_tensor_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTCNuFQgk71z"
      },
      "source": [
        "---\n",
        "## Atrybuty tensora\n",
        "Atrybuty tensora opisują jego kształt, typ danych oraz urządzenie, na którym tensor jest przechowywany."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LqGIHXCQLodT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 2])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_random.shape # kształt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bbzC8sKHLoa5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_random.dtype # typ danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xktGPB7wlutO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_random.device # urządzenie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdDKEOXVl1dv"
      },
      "source": [
        "Tensor można przenieść do karty graficznej (GPU) lub innego urządzenia wspierającego operacje [CUDA](https://pl.wikipedia.org/wiki/CUDA) \\(np. [TPU](https://en.wikipedia.org/wiki/Tensor_Processing_Unit)\\), o ile jest dostępne."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Ah9SrgQ9mApl"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available(): # metoda sprawdzająca dostępność urządzenia CUDA (GPU lub TPU)\n",
        "  tensor_cuda = tensor_random.to('cuda') # metoda przenosi tensor na wybrane urządzenie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "u5r63BEtocuJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.1168, 0.6626],\n",
              "         [0.5643, 0.6338],\n",
              "         [0.3534, 0.6778]],\n",
              "\n",
              "        [[0.3875, 0.9981],\n",
              "         [0.0128, 0.6430],\n",
              "         [0.1802, 0.5637]]], device='cuda:0')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0H8N3nmqXGJ"
      },
      "source": [
        "---\n",
        "**ZADANIE 3**\n",
        "\n",
        "Przenieś na GPU tensory z zadania 1 i 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1S2XPrKUqlbR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0), device(type='cuda', index=0))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# zadanie 3\n",
        "my_tensor_cuda = my_tensor.to('cuda')\n",
        "my_tensor_cuda2 = my_tensor_2.to('cuda')\n",
        "my_tensor_cuda.device, my_tensor_cuda2.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zskhODEWqnjR"
      },
      "source": [
        "---\n",
        "# Operacje na tensorach\n",
        "Wiele operacji na tensorach w PyTorch jest bardzo podobnych do operacji w NumPy. Niektóre przykłady będą zawierały analogie przedstawione na tablicach NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSZ1eGqnrZvo"
      },
      "source": [
        "### Indeksowanie\n",
        "Najpierw utworzone zostaną dwie zmienne: **tensor** przechowująca tensor o wymiarach 3x4 oraz **array** będącą tablicą NumPy utworzoną na podstawie **tensor**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "N_CoZ0uCrRfj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.zeros(3,4)\n",
        "array = tensor.numpy()\n",
        "print(tensor)\n",
        "print(array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3yFerI_sRzd"
      },
      "source": [
        "### Modyfikacja elementu o podanym indeksie\n",
        "Indeksy działają analogicznie jak w przypadku [tablic NumPy](https://numpy.org/doc/stable/reference/arrays.indexing.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "PC9goRyJr7WY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "tensor[1,2] = 1\n",
        "array[1,2] = 1\n",
        "print(tensor)\n",
        "print(array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkVEnAXPtWpt"
      },
      "source": [
        "### Wydzielenie fragmentu tensora/tablicy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wqsjuK93th4t"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor[:,2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "T89uqRZZtubX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array[1:3,1:4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rrf_H1FpuTYC"
      },
      "source": [
        "### Łączenie tensorów\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qJkjtJR7u8zt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1 = torch.zeros(3,2)\n",
        "t2 = torch.ones(3,1)\n",
        "t3 = torch.cat([t1, t2, t1], dim=1)\n",
        "t3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZXvyJlhqxPY"
      },
      "source": [
        "---\n",
        "**ZADANIE 4**\n",
        "\n",
        "Zdefiniuj w postaci tensorów macierze A i B:\n",
        "\n",
        "$A = \\begin{bmatrix}\n",
        "0 & 0 & 0 & 0 & 0\\\\\n",
        "0 & 0 & 0 & 1 & 2\\\\\n",
        "0 & 0 & 0 & 1 & 2\\\\\n",
        "0 & 0 & 0 & 1 & 2\\\\\n",
        "0 & 0 & 0 & 0 & 0\\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "$B = \\begin{bmatrix}\n",
        "0 & 0 & 0 & 0 & 0\\\\\n",
        "0 & 0 & 0 & 0 & 0\\\\\n",
        "0 & 0 & 3 & 4 & 0\\\\\n",
        "0 & 0 & 3 & 4 & 0\\\\\n",
        "0 & 0 & 3 & 4 & 0\\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "Wykorzystując poznane operacje tensorowe na macierzach A i B, utwórz tensor C, reprezentujący następującą macierz:\n",
        "$C = \\begin{bmatrix}\n",
        "1 & 2 & 3 & 4\\\\\n",
        "1 & 2 & 3 & 4\\\\\n",
        "1 & 2 & 3 & 4\\\\\n",
        "\\end{bmatrix}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "fs3TS35kuI95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3., 4.],\n",
              "        [1., 2., 3., 4.],\n",
              "        [1., 2., 3., 4.]])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# zadanie 4\n",
        "shape = (5, 5)\n",
        "A = torch.zeros(shape)\n",
        "A[1:4, 3] = 1 \n",
        "A[1:4, 4] = 2 \n",
        "\n",
        "B = torch.zeros(shape)\n",
        "B[2:, 2] = 3\n",
        "B[2:, 3] = 4 \n",
        "\n",
        "C = torch.concat([A[1:4, 3:], B[2:, 2:4]], dim=1)\n",
        "C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pbKHZ2Kt-2l"
      },
      "source": [
        "---\n",
        "### Mnożenie tensorów\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "oWt4oOMOwL0J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [2, 3]])\n",
            "tensor([[2, 5],\n",
            "        [3, 6],\n",
            "        [4, 7]])\n",
            "tensor([[2, 3]])\n",
            "tensor([[ 2, 10],\n",
            "        [ 9, 24],\n",
            "        [ 8, 21]])\n",
            "tensor([[ 2,  6],\n",
            "        [ 6, 12],\n",
            "        [ 4,  9]])\n",
            "tensor([[ 5, 10],\n",
            "        [15, 20],\n",
            "        [10, 15]])\n"
          ]
        }
      ],
      "source": [
        "# zdefiniowanie 3 przykładowych tensorów\n",
        "t1 = torch.tensor([[1,2],[3,4],[2,3]])\n",
        "t2 = torch.tensor([[2,5],[3,6],[4,7]])\n",
        "t3 = torch.tensor([[2,3]])\n",
        "\n",
        "# mnożenie dwóch tensorów (Uwaga! To nie jest mnożenie macierzowe znane z algebry!)\n",
        "t4 = t1.mul(t2)\n",
        "t5 = t1.mul(t3)\n",
        "\n",
        "# mnożenie macierzy przez liczbę\n",
        "t6 = t1.mul(5)\n",
        "print(t1)\n",
        "print(t2)\n",
        "print(t3)\n",
        "print(t4)\n",
        "print(t5)\n",
        "print(t6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Ix895XVuzb4j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2, 10],\n",
            "        [ 9, 24],\n",
            "        [ 8, 21]])\n",
            "tensor([[ 2,  6],\n",
            "        [ 6, 12],\n",
            "        [ 4,  9]])\n",
            "tensor([[ 5, 10],\n",
            "        [15, 20],\n",
            "        [10, 15]])\n"
          ]
        }
      ],
      "source": [
        "# alternatywnie dla powyższych operatorów, można zapisać:\n",
        "t4 = t1 * t2\n",
        "t5 = t1 * t3\n",
        "t6 = t1 * 5\n",
        "print(t4)\n",
        "print(t5)\n",
        "print(t6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "3Zag88N6006n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [2, 3]])\n",
            "tensor([[1, 3, 2],\n",
            "        [2, 4, 3]])\n"
          ]
        }
      ],
      "source": [
        "# transpozycja macierzy\n",
        "print(t1)\n",
        "print(t1.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9v1IXGt0Dl9"
      },
      "source": [
        "---\n",
        "**ZADANIE 5**\n",
        "\n",
        "Zdefiniuj t3 jako tensor [[2,3,4]] i powtórz powyższe operacje korzystające z t3. Co możesz zrobić z tensorem t3, żeby operacje wykonały się prawidłowo? Co się stanie, jeśli przeniesiesz wyłącznie t3 na GPU i powtórzysz operacje, które wykonywały się prawidłowo?\n",
        "\n",
        "\n",
        "https://numpy.org/doc/stable/user/basics.broadcasting.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "0OGqBDpC2EAd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 2,  4],\n",
              "         [ 9, 12],\n",
              "         [ 8, 12]]),\n",
              " tensor([[ 4, 10],\n",
              "         [ 9, 18],\n",
              "         [16, 28]]))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# zadanie 5\n",
        "t3 = torch.tensor([[2, 3, 4]]) # (1, 3)\n",
        "t4_ = t3.T * t1  # (3, 1) x (3, 2)\n",
        "t5_ = t3.T * t2 \n",
        "t4_, t5_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "dostajemy błąd bo nie jest w stanie przemnożyć dwóch maxierzy na innych urządzeniach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[48], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m t3_cuda \u001b[38;5;241m=\u001b[39m t3\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m t4_c \u001b[38;5;241m=\u001b[39m \u001b[43mt3_cuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "t3_cuda = t3.to('cuda')\n",
        "t4_c = t3_cuda.T * t1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHfM5C1Yzcvh"
      },
      "source": [
        "---\n",
        "### Mnożenie macierzowe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "TqFbk2B90EMw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t1:  tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [2, 3]])\n",
            "tensor([[2, 5],\n",
            "        [3, 6],\n",
            "        [4, 7]])\n",
            "tensor([[2, 3, 4],\n",
            "        [5, 6, 7]])\n",
            "tensor([[12, 15, 18],\n",
            "        [26, 33, 40],\n",
            "        [19, 24, 29]])\n"
          ]
        }
      ],
      "source": [
        "# Mnożenie macierzowe wykonywane jest w następujący sposób:\n",
        "print('t1: ', t1)\n",
        "print(t2)\n",
        "print(t2.T)\n",
        "print(t1.matmul(t2.T))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "MwJdlffv0-li"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[12, 15, 18],\n",
            "        [26, 33, 40],\n",
            "        [19, 24, 29]])\n"
          ]
        }
      ],
      "source": [
        "# Zapis alternatywny:\n",
        "print(t1 @ t2.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53wbnT4k1UOE"
      },
      "source": [
        "### Operacje \"w miejscu\" (in-place)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "WVvrR4iE1ZYS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [2, 3]])\n",
            "tensor([[6, 7],\n",
            "        [8, 9],\n",
            "        [7, 8]])\n",
            "tensor([[12, 14],\n",
            "        [16, 18],\n",
            "        [14, 16]])\n"
          ]
        }
      ],
      "source": [
        "# Uwaga! Operacje w miejscu pomagają oszczędzić pamięć, ale mogą nadpisać wartości potrzebne do wyznaczania gradientu.\n",
        "# Więcej informacji można znaleźć tu: https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd\n",
        "\n",
        "# Operacje w miejscu są zdefiniowane z sufiksem \"_\"\n",
        "print(t1)\n",
        "t1.add_(5)\n",
        "print(t1)\n",
        "t1.mul_(2)\n",
        "print(t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxPGNEJ_CYsn"
      },
      "source": [
        "### Pełna lista operacji tensorowych\n",
        "\n",
        "Z pełną listą operacji tensorowych można zapoznać się tutaj:\n",
        "\n",
        "https://pytorch.org/docs/stable/torch.html#\n",
        "\n",
        "---\n",
        "**ZADANIE 6**\n",
        "\n",
        "Na podstawie [dokumentacji PyTorch](https://pytorch.org/docs/stable/torch.html#) znajdź operator, przy pomocy którego zrealizujesz następujące przekształcenia:\n",
        "\n",
        "A.\n",
        "$\\begin{bmatrix}\n",
        "1 & 2 & 3 \\\\\n",
        "4 & 5 & 6 \\\\\n",
        "7 & 8 & 9 \\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 3 \\\\\n",
        "0 & 5 & 0 \\\\\n",
        "7 & 0 & 9 \\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "B.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "2 & 0 & 1 & 4 & 3\\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "C.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "8 & 9 & 7 & 8 & 9\\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "D.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "18 & 26 & 22 & 25 & 22\\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "E.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "F.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "False & True & True & False & False\\\\\n",
        "True & False & False & True & True\\\\\n",
        "False & True & False & False & False\\\\\n",
        "False & True & False & True & True\\\\\n",
        "False & True & True & True & False\\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "G.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "8 & 5 & 3 & 2 & 1\\\\\n",
        "9 & 8 & 5 & 4 & 2\\\\\n",
        "7 & 4 & 3 & 2 & 1\\\\\n",
        "8 & 7 & 6 & 3 & 2\\\\\n",
        "9 & 6 & 5 & 2 & 1\\\\\n",
        "\\end{bmatrix},\n",
        "\\begin{bmatrix}\n",
        "2 & 1 & 3 & 0 & 4\\\\\n",
        "0 & 4 & 3 & 2 & 1\\\\\n",
        "1 & 0 & 4 & 3 & 2\\\\\n",
        "4 & 1 & 3 & 2 & 0\\\\\n",
        "3 & 2 & 1 & 4 & 0\\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "H.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "8 & 5 \\\\\n",
        "9 & 8 \\\\\n",
        "7 & 4 \\\\\n",
        "8 & 7 \\\\\n",
        "9 & 6 \\\\\n",
        "\\end{bmatrix},\n",
        "\\begin{bmatrix}\n",
        "2 & 1 \\\\\n",
        "0 & 4 \\\\\n",
        "1 & 0 \\\\\n",
        "4 & 1 \\\\\n",
        "3 & 2 \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "I.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "2 & 7 & 15 & 18 & 19\\\\\n",
        "9 & 11 & 15 & 20 & 28\\\\\n",
        "4 & 11 & 12 & 14 & 17\\\\\n",
        "2 & 9 & 12 & 18 & 26\\\\\n",
        "1 & 6 & 12 & 21 & 23\\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "J.\n",
        "$\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "2 & 3 \\\\\n",
        "3 & 4 \\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 2 & 3 & 3 & 4 \\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "K.\n",
        "$\\begin{bmatrix}\n",
        "2 & 5 & 8 & 3 & 1\\\\\n",
        "9 & 2 & 4 & 5 & 8\\\\\n",
        "4 & 7 & 1 & 2 & 3\\\\\n",
        "2 & 7 & 3 & 6 & 8\\\\\n",
        "1 & 5 & 6 & 9 & 2\\\\\n",
        "\\end{bmatrix} \\rightarrow\n",
        "\\begin{bmatrix}\n",
        "1 & 3 & 8 & 5 & 2\\\\\n",
        "8 & 5 & 4 & 2 & 9\\\\\n",
        "3 & 2 & 1 & 7 & 4\\\\\n",
        "8 & 6 & 3 & 7 & 2\\\\\n",
        "2 & 9 & 6 & 5 & 1\\\\\n",
        "\\end{bmatrix}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhLYW0xQCNkT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A.\n",
            "tensor([[1, 0, 3],\n",
            "        [0, 5, 0],\n",
            "        [7, 0, 9]])\n",
            "\n",
            "B.\n",
            "tensor([2, 0, 1, 4, 3])\n",
            "\n",
            "C.\n",
            "tensor([8, 9, 7, 8, 9])\n",
            "\n",
            "D.\n",
            "tensor([18, 26, 22, 25, 22])\n",
            "\n",
            "E.\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "\n",
            "F.\n",
            "tensor([[False,  True,  True, False, False],\n",
            "        [ True, False, False,  True,  True],\n",
            "        [False,  True, False, False, False],\n",
            "        [False,  True, False,  True,  True],\n",
            "        [False,  True,  True,  True, False]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#A.\n",
        "A = torch.tensor([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]\n",
        "])\n",
        "\n",
        "A_ = torch.where(A % 2 == 1, A, torch.zeros_like(A))\n",
        "print(f\"A.\\n{A_}\\n\")\n",
        "\n",
        "#B.\n",
        "B = torch.tensor([\n",
        "    [2, 5, 8, 3, 1],\n",
        "    [9, 2, 4, 5, 8],\n",
        "    [4, 7, 1, 2, 3],\n",
        "    [2, 7, 3, 6, 8],\n",
        "    [1, 5, 6, 9, 2]\n",
        "])\n",
        "B_ = B.max(dim=1)  # wzdłuż wymiaru kolumn obliczamy\n",
        "# można też argmax użyć\n",
        "print(f\"B.\\n{B_[1]}\\n\")\n",
        "\n",
        "#C.\n",
        "print(f\"C.\\n{B_[0]}\\n\")\n",
        "\n",
        "#D.\n",
        "D = B.sum(dim=0)  # wzdłuż wymiaru rzędów sumujemy\n",
        "print(f\"D.\\n{D}\\n\")\n",
        "\n",
        "#E.\n",
        "E = B.unique()\n",
        "print(f\"E.\\n{E}\\n\")\n",
        "\n",
        "#F.\n",
        "F = B >= 5\n",
        "print(f\"F.\\n{F}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "G.\n",
            "tensor([[8, 5, 3, 2, 1],\n",
            "        [9, 8, 5, 4, 2],\n",
            "        [7, 4, 3, 2, 1],\n",
            "        [8, 7, 6, 3, 2],\n",
            "        [9, 6, 5, 2, 1]])\n",
            "tensor([[2, 1, 3, 0, 4],\n",
            "        [0, 4, 3, 2, 1],\n",
            "        [1, 0, 4, 3, 2],\n",
            "        [4, 1, 3, 2, 0],\n",
            "        [3, 2, 1, 4, 0]])\n",
            "\n",
            "H.\n",
            "tensor([[8, 5],\n",
            "        [9, 8],\n",
            "        [7, 4],\n",
            "        [8, 7],\n",
            "        [9, 6]])\n",
            "tensor([[2, 1],\n",
            "        [0, 4],\n",
            "        [1, 0],\n",
            "        [4, 1],\n",
            "        [3, 2]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#G.\n",
        "G = B.sort(dim=1, descending=True) # sortujemy wzdłuż kolumn\n",
        "print(f\"G.\\n{G[0]}\\n{G[1]}\\n\")\n",
        "\n",
        "#H.\n",
        "H = B.sort(dim=1, descending=True)\n",
        "print(f\"H.\\n{H[0][:, :2]}\\n{H[1][:, :2]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I.\n",
            "tensor([[ 2,  7, 15, 18, 19],\n",
            "        [ 9, 11, 15, 20, 28],\n",
            "        [ 4, 11, 12, 14, 17],\n",
            "        [ 2,  9, 12, 18, 26],\n",
            "        [ 1,  6, 12, 21, 23]])\n",
            "\n",
            "J.\n",
            "tensor([1, 2, 2, 3, 3, 4])\n",
            "\n",
            "K.\n",
            "tensor([[1, 3, 8, 5, 2],\n",
            "        [8, 5, 4, 2, 9],\n",
            "        [3, 2, 1, 7, 4],\n",
            "        [8, 6, 3, 7, 2],\n",
            "        [2, 9, 6, 5, 1]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#I.\n",
        "I = B.cumsum(dim=1)\n",
        "print(f\"I.\\n{I}\\n\")\n",
        "\n",
        "#J.\n",
        "J = torch.tensor([[1, 2], [2, 3], [3, 4]])\n",
        "print(f\"J.\\n{J.flatten()}\\n\")\n",
        "\n",
        "#K.\n",
        "K = B.flip((1, ))\n",
        "print(f\"K.\\n{K}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jpef8xqKiyz"
      },
      "source": [
        "<a name=\"homework\"></a>\n",
        "# Zadanie domowe\n",
        "\n",
        "W ramach zadania domowego należy przygotować środowisko uruchomieniowe dla PyTorch. W tym celu należy zainstalować następujące elementy:\n",
        "\n",
        "\n",
        "*   [Python (wersja 3.x)](https://www.python.org/)\n",
        "*   [Sterowniki NVIDIA](https://www.nvidia.com/Download/index.aspx)\n",
        "*   [CUDA Toolkit 9.2-11.0](https://developer.nvidia.com/cuda-zone)\n",
        "*   [PyTorch 1.7.1](https://pytorch.org/)\n",
        "\n",
        "Dla osób nieposiadających GPU zalecane jest korzystanie z Google Colab.\n",
        "\n",
        "Przydatne instrukcje dla następujących systemów:\n",
        "\n",
        "\n",
        "*   [Ubuntu 20.04](https://varhowto.com/install-pytorch-ubuntu-20-04/)\n",
        "*   [Windows 10](https://pub.towardsai.net/installing-pytorch-with-cuda-support-on-windows-10-a38b1134535e)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlds",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
